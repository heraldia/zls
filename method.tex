\section{Method}

Now that the cashier-free supermarket has become a trend in the future development, and more and more businesses will join the ranks in the futures.
So in order to conform to the trend of development, we did a series of experiments to achieve "cashier-free supermarket", and we will try to apply it to reality.
It include make scene to simulate a real supermarket and use multi cameras to cover whole scene to get images which used to identity items types and number on shelves.
Then we combine them into a complete system.
We made this model through Unity3D, which is a cross-platform game engine developed, then we can use it to build our scene.


\subsection{Multi cameras and Build scene}

We will use the identification in daily supermarkets in our life, so we investigated any small and medium-sized supermarkets, such as FamilyMart, JOETEN, 7-ELEVEN.
We find that the general pattern of these supermarkets is used strip shelves and parallel emissions.
And then we draw lessons from their pattern, we use the Unity3D to achieve the scene.
We used multi cameras in our simulated scenario, and try to restore the real scene as much as possible.
The Multi cameras scene is based on field of view(FOV), the horizontal field of view(H-FOV) and vertical field of view(V-FOV)\cite{Ball88} determined the sharpness and size of the pictures what we get.

\begin{figure}[htbp]
\centerline{\includegraphics[width=2.5cm,scale=0.4]{HFOV.jpg} \includegraphics[width=2.5cm,scale=0.4]{VFOV.jpg}}
\caption{H-FOV and V-FOV .}
\label{fig}
\end{figure}

Fixed focal length lens, it can get the angel field of view(AFOV), and we can get different size of FOV through adjusting the focal length of the lens through different working distances.

\centerline{\includegraphics[width=5cm,scale=0.9]{AFOV-MA.jpg}}
\begin{figure}[htbp]
\centerline{\includegraphics[width=9cm,scale=0.9]{AFOV.jpg}}
\caption{The field of view of lens is related to focal length, f is the focal length, h is the horizontal dimension of the sensor.}
\label{fig}
\end{figure}

We can follow the specifications of the scene (shelves size, the length and width of walking, and layout of the whole scene) to adjust FOV.


\subsection{Cameras selected}

The terms "dots per inch" (DPI) and "pixels per inch"(PPI) are used interchangeably by many. A 200 dpi print means that for each inch of that printed material, it takes about 200 dots to make the picture. A pixel is like a square dot without gaps. Both of them can describe the quality of a picture, and some cameras save digital images in arbitrary values as 72 dpi. We can calculate the DPI or PPI for what we need page size in Fig.3.
\begin{figure}[htbp]
\centerline{\includegraphics[width=8cm,scale=0.9]{DPIPPI.jpg}}
\caption{Page Size and Optical Resolution}
\label{fig}
\end{figure}

FLEXIDOME IP panoramic 7000 MP, which has 12MP / 30 fps sensor for fine details with smooth motion and Intelligent Video Analysis on full panoramic overview. Panoramic surveillance offers full 180° or 360° coverage of the designated area. The 360° version of the camera, when mounted
centrally on a ceiling, gives complete wall-to-wall coverage. The 180° version has a higher effective resolution and is ideal for wall mounting or for ceiling
mounting in corridors.

When mounted at a height of 3.5 m (11.48 ft) the 360° version of the camera has the following coverage radius for the four levels in Fig.4.
\begin{figure}[htbp]
\centerline{\includegraphics[width=7cm,scale=0.8]{camera360.jpg}}
\caption{Page Size and Optical Resolution}
\label{fig}
\end{figure}

When mounted at a height of 3.5 m (11.48 ft) the 180° version of the camera has the following coverage radius for the four levels in Fig.5.
\begin{figure}[htbp]
\centerline{\includegraphics[width=7cm,scale=0.8]{camera180.jpg}}
\caption{Page Size and Optical Resolution}
\label{fig}
\end{figure}

The camera provides the full resolution circular image for recording even if we are viewing only a portion of the scene.
Unity3D is a game engine, the engine can be used to create both three-dimensional and two-dimensional games as well as simulations for its many platforms.
In our experiment, we use Unity3D to build a scene like a truth supermarket, and camera placement experiments are performed in this simulated scene.

\subsection{Item Recognition}

The main method current approaches to object recognition make essential use of machine learning methods and deep learning methods.
To achieve the item recognition, we can collect larger datasets, learn more powerful models, and use better techniques for preventing overfitting.
In order to achieve item recognition, we use the YOLOv3 method to train our datasets.
YOLO means "You only look once, real time object detection explained", it is a new item recognition method, now it has developed to the 3rd generation, it has more accurate recognition rate and ability to process larger amounts of data.
We will use the YOLOv3 to train image what we get, it is based on OpenCV3.40 and CUDA8.0.

A single GTX 1060 GPU has 6GB of memory, it is enough for us to train examples, therefore we spread the net across GPU.
We can use the Python Reptile to get image from Internet, then use visual GUI-software for marking bounded boxes of objects and generating annotation files.
It will create .txt-file for each .jpg-image-file in the same directory and with the same name, but with .txt-extension, and put to file: object number and object coordinates on this image, for each object in new line: object-class, x, y, width, height.

\subsection{sensor fusion}

